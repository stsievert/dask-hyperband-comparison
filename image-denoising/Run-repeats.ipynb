{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan for running experiments\n",
    "\n",
    "* Debug\n",
    "    * That thing with autoencoders?\n",
    "    * Check random_state (setting for models? Setting for dataset?)\n",
    "* Prepare for launch\n",
    "    * Make sure this notebook runs fine\n",
    "    * Run this notebook, have analysis to verify\n",
    "* Launch EC2 instances (instance type: XXX, Anaconda's AMI)\n",
    "    * Upgrade Dask\n",
    "    * Install PyTorch/Skorch\n",
    "    * Upgrade jupyter notebooks?\n",
    "    * Run Dask workers on each machine\n",
    "* Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:58557\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.59 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:58557' processes=4 cores=4>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import distributed\n",
    "from distributed import Client, LocalCluster\n",
    "#cluster = LocalCluster(n_workers=16)\n",
    "#client = Client(cluster)\n",
    "client = Client()#\"localhost:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# def debug_loop():\n",
    "#     subprocess.call(\"pip install git+https://github.com/stsievert/dask-ml@hyperband-scale\".split(\" \"))\n",
    "#     import dask_ml\n",
    "#     return dask_ml.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time debug_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.run(debug_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 185 ms, sys: 31.5 ms, total: 217 ms\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%time client.upload_file('autoencoder.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda3/lib/python3.6/site-packages/numba/errors.py:102: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.11.1.dev65+g1612e1f.d20190219'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask_ml\n",
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "import dask_ml\n",
    "dask_ml.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/scott/Developer/stsievert/dask-ml/dask_ml/__init__.py'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_ml.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "See below for an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noisy_mnist\n",
    "chunk_size = 70_000 // 3\n",
    "_X, _y = noisy_mnist.dataset(random_state=42)\n",
    "_X = _X[:chunk_size * 3]\n",
    "_y = _y[:chunk_size * 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69999, 784), dtype('float32'), 0.0, 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_X.shape, _X.dtype, _X.min(), _X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69999, 784), dtype('float32'), 0.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y.shape, _y.dtype, _y.min(), _y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dask.array<array, shape=(69999, 784), dtype=float32, chunksize=(23333, 784)>,\n",
       " dask.array<array, shape=(69999, 784), dtype=float32, chunksize=(23333, 784)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.array as da\n",
    "n, d = _X.shape\n",
    "X = da.from_array(_X, chunks=(n // 3, d))\n",
    "y = da.from_array(_y, chunks=n // 3)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.utils import check_random_state\n",
    "\n",
    "# rng = check_random_state(42)\n",
    "# cols = 8\n",
    "# w = 1.0\n",
    "# fig, axs = plt.subplots(figsize=(cols*w, 2*w), ncols=cols, nrows=2)\n",
    "# for col, (upper, lower) in enumerate(zip(axs[0], axs[1])):\n",
    "#     if col == 0:\n",
    "#         upper.text(-28, 14, 'ground\\ntruth')\n",
    "#         lower.text(-28, 14, 'input')\n",
    "#     i = rng.choice(len(X))\n",
    "#     noisy = X[i].reshape(28, 28)\n",
    "#     clean = y[i].reshape(28, 28)\n",
    "#     kwargs = {'cbar': False, 'xticklabels': False, 'yticklabels': False, 'cmap': 'gray_r'}\n",
    "#     sns.heatmap(noisy, ax=lower, **kwargs)\n",
    "#     sns.heatmap(clean, ax=upper, **kwargs)\n",
    "# plt.savefig(\"imgs/input-output.svg\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use a deep learning library (PyTorch) for this model, at least through the scikit-learn interface for PyTorch, [skorch].\n",
    "\n",
    "[skorch]:https://github.com/dnouri/skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder import Autoencoder, NegLossScore\n",
    "import torch\n",
    "# from sklearn.model_selection import ParameterSampler\n",
    "import torch\n",
    "\n",
    "def trim_params(**kwargs):\n",
    "    if kwargs['optimizer'] != 'Adam':\n",
    "        kwargs.pop('optimizer__amsgrad', None)\n",
    "    if kwargs['optimizer'] == 'Adam':\n",
    "        kwargs.pop('optimizer__lr', None)\n",
    "    if kwargs['optimizer'] != 'SGD':\n",
    "        kwargs.pop('optimizer__nesterov', None)\n",
    "        kwargs.pop('optimizer__momentum', None)\n",
    "    kwargs['optimizer'] = getattr(torch.optim, kwargs['optimizer'])\n",
    "    return kwargs\n",
    "\n",
    "class TrimParams(NegLossScore):\n",
    "    def set_params(self, **kwargs):\n",
    "        kwargs = trim_params(**kwargs)\n",
    "        return super().set_params(**kwargs)\n",
    "\n",
    "model = TrimParams(\n",
    "    module=Autoencoder,\n",
    "    criterion=torch.nn.BCELoss,\n",
    "    warm_start=True,\n",
    "    train_split=None,\n",
    "    max_epochs=1,\n",
    "    callbacks=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't show it here; I'd rather concentrate on tuning hyperparameters. But briefly, it's a simple fully connected 3 hidden layer autoencoder with a latent dimension of 49."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "The parameters I am interested in tuning are\n",
    "\n",
    "* model\n",
    "    * initialization\n",
    "    * activation function\n",
    "    * weight decay (which is similar to $\\ell_2$ regularization)\n",
    "* optimizer\n",
    "    * which optimizer to use (e.g., Adam, SGD)\n",
    "    * batch size used to approximate gradient\n",
    "    * learning rate (but not for Adam)\n",
    "    * momentum for SGD\n",
    "    \n",
    "After looking at the results, I think I was too exploratory in my tuning of step size. I should have experimented with it more to determine a reasonable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "params = {\n",
    "    'module__init': ['xavier_uniform_',\n",
    "                     'xavier_normal_',\n",
    "                     'kaiming_uniform_',\n",
    "                     'kaiming_normal_',\n",
    "                    ],\n",
    "    'module__activation': ['ReLU', 'LeakyReLU', 'ELU', 'PReLU'],\n",
    "    'optimizer': [\"SGD\"] * 5 + [\"Adam\"] * 2,\n",
    "    'batch_size': [32, 64, 128, 256, 512],\n",
    "    'optimizer__lr': np.logspace(1, -1.5, num=1000),\n",
    "    'optimizer__weight_decay': [0]*200 + np.logspace(-5, -3, num=1000).tolist(),\n",
    "    'optimizer__nesterov': [True],\n",
    "    'optimizer__momentum': np.linspace(0, 1, num=1000),\n",
    "    'train_split': [None],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am testing `optimizer` to be `SGD` or `Adam` to test \"[The Marginal Value of Adaptive Gradient Methods in Machine Learning][marginal]\". From their abstract,\n",
    "\n",
    "> We observe that the solutions found by adaptive methods generalize worse (often sig- nificantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.\n",
    "\n",
    "Their experiments in Figure 1b show that non-adaptive methods (SGD and heavy ball) perform much better than adaptive methods.\n",
    "\n",
    "They have to do some tuning for this. **Can we replicate their result?**\n",
    "\n",
    "[marginal]:https://arxiv.org/pdf/1705.08292.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging; ignore this cell\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import ParameterSampler\n",
    "# import dask.array as da\n",
    "# import numpy as np\n",
    "# model = SGDClassifier()\n",
    "# params = {'alpha': np.logspace(-7, 0, num=int(1e6))}\n",
    "\n",
    "# n, d = int(10e3), 784\n",
    "# _X, _y = make_classification(n_samples=n, n_features=d,\n",
    "#                              random_state=1)\n",
    "# X = da.from_array(_X, chunks=(n // 10, d))\n",
    "# y = da.from_array(_y, chunks=n // 10)\n",
    "# X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import msgpack\n",
    "import pandas as pd\n",
    "\n",
    "def fmt(obj):\n",
    "    if isinstance(obj, list):\n",
    "        return [fmt(v) for v in obj]\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: fmt(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "import msgpack\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def save_search(search, today, prefix, X, y, task_stream):\n",
    "    pre = f\"{today}-{prefix}-\"\n",
    "    print(\"    \" + prefix, search.best_score_)\n",
    "    with open(pre + \"test.npz\", \"wb\") as f:\n",
    "        y_hat = search.predict(X)\n",
    "        np.savez(f, X=X, y=y, y_hat=y_hat)\n",
    "    # skorch models aren't pickable\n",
    "    with open(pre + \"params.json\", \"w\") as f:\n",
    "        params = {k: fmt(v) for k, v in search.get_params().items() if \"estimator\" not in k and \"param_distribution\" not in k}\n",
    "        json.dump(params, f)\n",
    "    # with open(pre + \"best-model.joblib\", \"wb\") as f:\n",
    "    #     joblib.dump(search.best_estimator_, f)\n",
    "    with open(pre + \"best-params-and-score.json\", \"w\") as f:\n",
    "        json.dump({\"params\": search.best_params_, \"score\": search.best_score_}, f)\n",
    "\n",
    "    with open(pre + \"history.json\", 'w') as f:\n",
    "        json.dump(search.history_, f)\n",
    "\n",
    "    with open(pre + \"cv_results.json\", 'w') as f:\n",
    "        json.dump(fmt(search.cv_results_), f)\n",
    "     \n",
    "    timing_stats = client.profile(filename=pre + f\"profile-graph.html\")\n",
    "    with open(pre + f\"timing.json\", \"w\") as f:\n",
    "        json.dump(timing_stats[0], f)\n",
    "        \n",
    "    pd.DataFrame(task_stream.data).to_msgpack(pre + \"task-stream.msgpack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = \"2019-06-23/c5.4-v1\"\n",
    "today = \"_debug/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<array, shape=(69999, 784), dtype=float32, chunksize=(23333, 784)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23333, 23333, 23333), (784,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dask.array<concatenate, shape=(62997, 784), dtype=float32, chunksize=(20999, 784)>,\n",
       " dask.array<concatenate, shape=(7002, 784), dtype=float32, chunksize=(2334, 784)>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.array<concatenate, shape=(62997, 784), dtype=float32, chunksize=(20999, 784)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "max_iter = 243\n",
    "history = {}\n",
    "cv_results = {}\n",
    "searches = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "\n",
    "fit_params = {}\n",
    "if isinstance(model, SGDClassifier):\n",
    "    fit_params = {'classes': da.unique(y).compute()}\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import IncrementalSearchCV\n",
    "from time import time\n",
    "from distributed import get_task_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(model, params, max_iter, client, fit_params=None, random_state=None):\n",
    "    if fit_params is None:\n",
    "        fit_params = {}\n",
    "    assert isinstance(random_state, int)\n",
    "    \n",
    "    print(\"    starting patience\")\n",
    "    num_calls = 243\n",
    "    num_models = 25\n",
    "    start = time()\n",
    "    patience = IncrementalSearchCV(\n",
    "        model,\n",
    "        params,\n",
    "        decay_rate=0,\n",
    "        patience=max_iter // 10,\n",
    "        n_initial_parameters=3 * num_models,\n",
    "        max_iter=num_calls,\n",
    "        random_state=random_state,\n",
    "        scores_per_fit=10,\n",
    "    )\n",
    "    with get_task_stream() as ts:\n",
    "        patience.fit(X_train, y_train, **fit_params)\n",
    "    save_search(patience, today, f\"patience-{random_state}\", X_test.compute(), y_test.compute(), ts)\n",
    "    print(f\"    patience {random_state} done in {time() - start:0.2f}\")\n",
    "    print(\"starting hyperband\")\n",
    "    start = time()\n",
    "    # Hyperband\n",
    "    hyperband = HyperbandSearchCV(\n",
    "        model,\n",
    "        params,\n",
    "        max_iter=max_iter,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    with get_task_stream() as ts:\n",
    "        hyperband.fit(X_train, y_train, **fit_params)\n",
    "    save_search(hyperband, today, f\"hyperband-{random_state}\", X_test.compute(), y_test.compute(), ts)\n",
    "    print(f\"    hyperband {random_state} done in {time() - start:0.2f}\")\n",
    "\n",
    "    print(\"    starting hyperband+sop\")\n",
    "    start = time()\n",
    "    h_sop = HyperbandSearchCV(\n",
    "        model,\n",
    "        params,\n",
    "        max_iter=max_iter,\n",
    "        random_state=random_state,\n",
    "        patience=True,\n",
    "    )\n",
    "    with get_task_stream() as ts:\n",
    "        h_sop.fit(X_train, y_train, **fit_params)\n",
    "    save_search(h_sop, today, f\"hyperband-w-patience-{random_state}\", X_test.compute(), y_test.compute(), ts)\n",
    "    print(f\"    hyperband+sop {random_state} done in {time() - start:0.2f}\")\n",
    "\n",
    "    total_calls = hyperband.metadata['partial_fit_calls']\n",
    "    num_calls = max_iter\n",
    "\n",
    "    n_workers = 25 or len(client.cluster.workers)\n",
    "    num_models = max(n_workers, total_calls // num_calls)\n",
    "    assert num_calls == 243\n",
    "    assert num_models == 25\n",
    "    assert hyperband.metadata[\"partial_fit_calls\"] == 4743\n",
    "\n",
    "\n",
    "\n",
    "    return None #hyperband, h_sop, passive, patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patience = 243 // 10\n",
    "patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from time import sleep\n",
    "class LinearFunction(BaseEstimator):\n",
    "    def __init__(self, intercept=0, slope=1, **kwargs):\n",
    "        self.intercept = intercept\n",
    "        self.slope = slope\n",
    "        self._partial_fit_calls = 0\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    def partial_fit(self, X, y):\n",
    "        self._partial_fit_calls += 1\n",
    "        sleep(0.05)\n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.slope * self._partial_fit_calls + self.intercept\n",
    "    def predict(self, X):\n",
    "        return self.slope * self._partial_fit_calls + self.intercept\n",
    "        \n",
    "model = LinearFunction()\n",
    "params = {\"slope\": np.linspace(0, 0.0005 / 25, num=1000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    starting patience\n",
      "best score is 0.000 after 1 calls\n",
      "best score is 0.000 after 11 calls\n",
      "best score is 0.000 after 21 calls\n",
      "best score is 0.001 after 31 calls\n",
      "    patience-0 0.0006181381381381381\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The wrapped estimator 'LinearFunction(intercept=0, slope=1.993993993993994e-05)' does not have a 'predict' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ba6fd932fc9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"comparison {random_state} done in {time() - start:0.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-e7160dfdeb37>\u001b[0m in \u001b[0;36mrun_comparison\u001b[0;34m(model, params, max_iter, client, fit_params, random_state)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_task_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpatience\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msave_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"patience-{random_state}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"    patience {random_state} done in {time() - start:0.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"starting hyperband\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f281e420cb88>\u001b[0m in \u001b[0;36msave_search\u001b[0;34m(search, today, prefix, X, y, task_stream)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"test.npz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# skorch models aren't pickable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/stsievert/dask-ml/dask_ml/wrappers.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \"\"\"\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/stsievert/dask-ml/dask_ml/wrappers.py\u001b[0m in \u001b[0;36m_check_method\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             )\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: The wrapped estimator 'LinearFunction(intercept=0, slope=1.993993993993994e-05)' does not have a 'predict' method."
     ]
    }
   ],
   "source": [
    "\n",
    "random_state = 0\n",
    "start = time()\n",
    "_ = run_comparison(model, params, max_iter, client, random_state=random_state, fit_params=fit_params)\n",
    "print(f\"comparison {random_state} done in {time() - start:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_stats = client.profile()\n",
    "\n",
    "with open(\"final-timings.json\", \"w\") as f:\n",
    "    json.dump(timing_stats, f)\n",
    "\n",
    "data, fig = client.get_task_stream(plot=True)\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.plotting.figure.Figure\">Figure</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'bk-task-stream-plot', <span id=\"1281\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">above&nbsp;=&nbsp;[],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_scale&nbsp;=&nbsp;1,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">background_fill_color&nbsp;=&nbsp;{'value': '#ffffff'},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">below&nbsp;=&nbsp;[DatetimeAxis(id='1246', ...)],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">border_fill_color&nbsp;=&nbsp;{'value': '#ffffff'},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;[],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_x_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">extra_y_ranges&nbsp;=&nbsp;{},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">h_symmetry&nbsp;=&nbsp;True,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;None,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">hidpi&nbsp;=&nbsp;True,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">left&nbsp;=&nbsp;[LinearAxis(id='1251', ...)],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_factor&nbsp;=&nbsp;10,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_interval&nbsp;=&nbsp;300,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_threshold&nbsp;=&nbsp;2000,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">lod_timeout&nbsp;=&nbsp;500,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">match_aspect&nbsp;=&nbsp;False,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border&nbsp;=&nbsp;5,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_bottom&nbsp;=&nbsp;None,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_left&nbsp;=&nbsp;None,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_right&nbsp;=&nbsp;35,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_border_top&nbsp;=&nbsp;None,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;'task_stream',</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_alpha&nbsp;=&nbsp;{'value': 1.0},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_cap&nbsp;=&nbsp;'butt',</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_color&nbsp;=&nbsp;{'value': '#e5e5e5'},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash&nbsp;=&nbsp;[],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_dash_offset&nbsp;=&nbsp;0,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_join&nbsp;=&nbsp;'bevel',</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">outline_line_width&nbsp;=&nbsp;{'value': 1},</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">output_backend&nbsp;=&nbsp;'canvas',</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_height&nbsp;=&nbsp;600,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">plot_width&nbsp;=&nbsp;600,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">renderers&nbsp;=&nbsp;[DatetimeAxis(id='1246', ...), Grid(id='1250', ...), LinearAxis(id='1251', ...), Grid(id='1255', ...), GlyphRenderer(id='1260', ...), BoxAnnotation(id='1271', ...)],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">right&nbsp;=&nbsp;[],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;'stretch_both',</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;[],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title&nbsp;=&nbsp;Title(id='1237', ...),</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">title_location&nbsp;=&nbsp;'above',</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar&nbsp;=&nbsp;Toolbar(id='1256', ...),</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_location&nbsp;=&nbsp;'above',</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_sticky&nbsp;=&nbsp;True,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">v_symmetry&nbsp;=&nbsp;False,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;None,</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_range&nbsp;=&nbsp;DataRange1d(id='1235', ...),</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">x_scale&nbsp;=&nbsp;LinearScale(id='1242', ...),</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_range&nbsp;=&nbsp;DataRange1d(id='1236', ...),</div></div><div class=\"1280\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">y_scale&nbsp;=&nbsp;LinearScale(id='1244', ...))</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  var expanded = false;\n",
       "  var ellipsis = document.getElementById(\"1281\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    var rows = document.getElementsByClassName(\"1280\");\n",
       "    for (var i = 0; i < rows.length; i++) {\n",
       "      var el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "Figure(id='bk-task-stream-plot', ...)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>nbytes</th>\n",
       "      <th>startstops</th>\n",
       "      <th>status</th>\n",
       "      <th>thread</th>\n",
       "      <th>type</th>\n",
       "      <th>worker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dict-583ab4d6-cc20-4bde-951a-c2854be3b2ce</td>\n",
       "      <td>240</td>\n",
       "      <td>((compute, 1553435505.039325, 1553435505.03934...</td>\n",
       "      <td>OK</td>\n",
       "      <td>140036838618880</td>\n",
       "      <td>b'\\x80\\x04\\x95\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>tcp://172.31.25.234:45003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dict-fb5ab1f4-d792-446d-b9a6-1eea3a78f379</td>\n",
       "      <td>240</td>\n",
       "      <td>((compute, 1553435505.0397773, 1553435505.0397...</td>\n",
       "      <td>OK</td>\n",
       "      <td>139998560577280</td>\n",
       "      <td>b'\\x80\\x04\\x95\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>tcp://172.31.18.35:46685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_create_model-d4908a4e892a1a4c21ea76b6015127a1</td>\n",
       "      <td>360</td>\n",
       "      <td>((compute, 1553435505.0285432, 1553435505.0482...</td>\n",
       "      <td>OK</td>\n",
       "      <td>140393498208000</td>\n",
       "      <td>b'\\x80\\x04\\x95\\x16\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>tcp://172.31.22.106:41967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_create_model-ad3285c9b623bb50ebefa67632be0e83</td>\n",
       "      <td>360</td>\n",
       "      <td>((compute, 1553435505.02852, 1553435505.048227...</td>\n",
       "      <td>OK</td>\n",
       "      <td>140393498470144</td>\n",
       "      <td>b'\\x80\\x04\\x95\\x16\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>tcp://172.31.22.106:40967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_create_model-f426d78a1fbbc129561420a60c0160a5</td>\n",
       "      <td>360</td>\n",
       "      <td>((compute, 1553435505.027857, 1553435505.04965...</td>\n",
       "      <td>OK</td>\n",
       "      <td>140393498732288</td>\n",
       "      <td>b'\\x80\\x04\\x95\\x16\\x00\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>tcp://172.31.22.106:35363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              key  nbytes  \\\n",
       "0       dict-583ab4d6-cc20-4bde-951a-c2854be3b2ce     240   \n",
       "1       dict-fb5ab1f4-d792-446d-b9a6-1eea3a78f379     240   \n",
       "2  _create_model-d4908a4e892a1a4c21ea76b6015127a1     360   \n",
       "3  _create_model-ad3285c9b623bb50ebefa67632be0e83     360   \n",
       "4  _create_model-f426d78a1fbbc129561420a60c0160a5     360   \n",
       "\n",
       "                                          startstops status           thread  \\\n",
       "0  ((compute, 1553435505.039325, 1553435505.03934...     OK  140036838618880   \n",
       "1  ((compute, 1553435505.0397773, 1553435505.0397...     OK  139998560577280   \n",
       "2  ((compute, 1553435505.0285432, 1553435505.0482...     OK  140393498208000   \n",
       "3  ((compute, 1553435505.02852, 1553435505.048227...     OK  140393498470144   \n",
       "4  ((compute, 1553435505.027857, 1553435505.04965...     OK  140393498732288   \n",
       "\n",
       "                                                type  \\\n",
       "0  b'\\x80\\x04\\x95\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "1  b'\\x80\\x04\\x95\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "2  b'\\x80\\x04\\x95\\x16\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "3  b'\\x80\\x04\\x95\\x16\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "4  b'\\x80\\x04\\x95\\x16\\x00\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "\n",
       "                      worker  \n",
       "0  tcp://172.31.25.234:45003  \n",
       "1   tcp://172.31.18.35:46685  \n",
       "2  tcp://172.31.22.106:41967  \n",
       "3  tcp://172.31.22.106:40967  \n",
       "4  tcp://172.31.22.106:35363  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_msgpack(\"times.msgpack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42609"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
